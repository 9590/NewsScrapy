
scrapy startproject peojectname

apt-get install Python-bs4

from bs4 import BeautifulSoup

scrapy crawl thepaper | more

from scrapy.downloadermiddlewares.useragent import UserAgentMiddleware

import logging
logger = logging.getLogger('USerAgent')
logger.info("msg")

request = scrapy.Request("http://www.example.com/some_page.html",
                             callback=self.parse_page2)

scrapy crawl meadin -o meadin.json

scrapy crawl meadin -o log/meadin.json --logfile log/meadin.log


-------------------------------------------------
#BeautifulSoup

sopu.find(name="tag", attrs={"attr1": True});

soup.select('div[class="news_li"]')

.has_attr("lasttime")

PageElement.replace_with()

unicode(news_list[1].p)

如果tag中包含多个字符串 [2] ,可以使用 .strings 来循环获取:

-------------------------------------------------
#re

re.search(pattern, string, flags)

re.sub(pattern, repl, string, count)

re.split(r'\s+', text)；


------------------------------------------------
#time,datetime
time.strptime(date,"%Y-%m-%d")

datetime.datetime.combine(datetime.date.today(), datetime.time.min) #当天0点

datetime.datetime.now()

datetime.datetime.strptime(news_date.encode('utf-8'),"%Y年%m月%d日 %H:%M:%S")


datetime.timedelta.days
